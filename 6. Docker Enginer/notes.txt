Docker Engine is referred to as a host with Docker installed on it. When you install Docker on a linux
host, you actually install 3 different components: Docker CLI, REST API, Docker Deamon. 

Docker Deamon is a background process that manages docker objects such as the images, containers, volumes
and networks. The Docker REST API server that programs can use to talk to the deamon and provide 
instructions. Docker CLI is nothing but a command line interface which we have been using till now to 
perform actions such as running a container, stoppping containers. Docker CLI uses REST API to interact
with the Docker Deamon. Docker CLI need not necessarily be on the same host. It can be on another 
system like a laptop and can still work with a remote Docker Engine.

To run a container on a remote docker host, run the following command.
Command: docker -H=ipa:port run nginx

---------------------------------------------------------------------
The process of containerization

Docker uses namespace to isolate workspace.

The underlying host as well as the containers share the same system resources as CPU and memory.
By default, there is no restriction as to how much of a resource a container can use and hence a 
container may end up utilizing all of the resources on the underlying host. There is a way to restrict
the amount of CPU or memory a container can use. 

Command: docker run --cpus=.5 ubuntu
Explaination: this command ensures that the container does not take up more than 50% of the host CPU
at any given time.

Command: docker run --memory=100m ubuntu
Explaination: this command ensures that the container can use a maximum of 100MB of memory

-------------------------------------------------------------------------------------
Docker Storage and File System

How does docker stores data on the local file system?

When you install docker on a system, it creates this folder structure at var/lib/docker. You have 
multiple folders under it called aufs, containers, image, volume, etc. This is where docker stores
all its data by default. (data means, files related to images and containers running on the docker host)


Docker Layered Architecture

Docker build images in a layered architecture. Each line of instruction in the docker file creates
a new layer in the docker image with just the changes from the previous layer. If docker is supposed
to create another image from another dockerfile, if it has a particular layer in cache, it will use
it instead of creating a new layer. Similarly, if you happen to update a small change in your application
code, then docker utilizes previous cache to rebuild the image, instead of rebuilding the image from 
scratch. 

Once the image build is complete, you cannot modify the contents of these layers and so there are read
only and you can only modify them by initiating a new build. When you run a container, docker creates
a new writable container layer on top of image layers. The writable layer is used to store data created
by the containers such as log files by the applications, any temporary files generated by the containers
or just any files modified by the user on that container. The life of this layer is only as long as the 
container is alive. When the container is destroyed, this layer and all of the changes stored in it are
also destroyed. If we run multiple containers based off of one image, then all the containers share the
same image layer. 

If we login to the newly created container and create a new file. It would be created in the container
layer which is read and write. Files in the image layer are read only, you cannot edit anything in those
layers.

If we wish to modify the source code of our application. The same image layer may be shared between 
multiple containers created from this image. So does it mean that we cannot modify the file inside this
container? No, we can. We can modify the source code, but before we save the modified file, Docker
automatically creates a copy of the file in the read write layer and we will be modifying the file stored
in read write layer (ie the container layer). All future modifications will be done on this copy of 
read write layer. This is called copy on write mechanism. The image will remain the same, until you
rebuild the image. What happens when we get rid of the container? All of the data that was stored in the 
container layer also gets deleted. What if we wish to persist this data? For example, if we were working
with a database and we would like to preserve the data created by the container, we could add a 
persistent volume to the container. To do this, first create a volume using the docker volume create 
command. 
Command: docker volume create data_volume
Explaination: this command creates a folder 'data_volume' under /var/lib/docker/volumes